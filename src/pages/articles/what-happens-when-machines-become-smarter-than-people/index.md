---
title: "What Happens When Machines Become Smarter than People?"
description: "Philosopher Daniel Dennett on why the real danger of AI is not its potential hyper-intelligence. The real danger is its incompetence."
image: "./dennettmachines.jpg"
imageAlt: "typing keyboard daniel dennett"
imageSeo: "./dennettmachines.jpg"
tags: ["AI", "Singularity", "Daniel Dennett", "David J. Chalmers"]
date: "2024-02-20"
author: "Jack Maden"
authorPic: "./philosophybreak.png"
authorLink: "/about/"
---

<span class="big-letter">W</span>ill machines one day turn on humanity? Will we become slaves, prey, or simply ‘surplus to requirements’ for a superior artificial intelligence?

While such questions may seem to belong to the realm of science fiction, the world-ending potential of AI is becoming an increasingly urgent topic of public and policymaker discussion — mostly due to the rapid ongoing development of popular technologies like ChatGPT.

The more extreme concerns around AI involve what’s known as the ‘singularity’, a hypothetical point at which the growth of machine intelligence becomes uncontrollable and irreversible.

## The singularity: might we lose control of AI?

<span class="big-letter">I</span>n his 2010 paper [​The Singularity: A Philosophical Analysis​](https://philpapers.org/rec/CHATSA), the philosopher David Chalmers succinctly describes the singularity as follows:

>What happens when machines become more intelligent than humans? One view is that this event will be followed by an explosion to ever-greater levels of intelligence, as each generation of machines creates more intelligent machines in turn. This intelligence explosion is now often known as the ‘singularity’.

In other words: if we’re capable of creating machines more intelligent than we are, then that generation of machines will in principle be capable of creating machines more intelligent again. 

This could lead to an exponential situation — the singularity — where human intelligence is quickly and irretrievably left far behind by machine intelligence.

The main worry is that, if such a singularity event were to occur, we’d no longer have authority or control over what happens in society, for the goals, objectives, and actions of a superintelligent AI would not be predictable by us.

Perhaps the AI would channel all our electricity to power its own intellectual projects. Maybe it would decide to hack our military systems and detonate every single nuclear bomb at once. Vast swathes of humanity could be sacrificed — purposefully or indifferently — in aid of some goal or objective that no human could possibly understand.

While influential figures across AI research and various governments express real concern about the singularity, however, American philosopher Daniel Dennett doesn’t buy it.

In the final chapter of his book <a target="_blank" rel="noopener noreferrer sponsored" href="https://www.amazon.com/Bacteria-Bach-Back-Evolution-Minds-ebook/dp/B01HDSU2KY?&linkCode=ll1&tag=philosophybre-20&linkId=ed980bd711d48ce0e2e40cdd4c651278&language=en_US&ref_=as_li_ss_tl">From Bacteria to Bach and Back</a>, Dennett reflects on the role technology is playing and will come to play in our lives. As he puts it:

>I am not worried about humanity creating a race of super-intelligent agents destined to enslave us, but that does not mean I am not worried. I see other, less dramatic, but much more likely, scenarios in the immediate future that are cause for concern and call for immediate action.

## Our reliance on AI could lead to negligence

<span class="big-letter">F</span>or Dennett, while a singularity event remains possible in principle, “the task is orders of magnitude larger and more difficult than the cheerleaders have claimed.”

Dennett argues that smart technology presents us with more practical threats that have a far higher likelihood of occuring. As he clarifies:

>The real danger, I think, is not that machines more intelligent than we are will usurp our role as captains of our destinies, but that we will _over-estimate_ the comprehension of our latest thinking tools, prematurely ceding authority to them far beyond their competence.

Take transport. It’s not just aviation and shipping industries that depend on GPS for safe and efficient navigation: how many individuals now turn to their smartphones instead of using a road map?

Alternatively, take medicine. Computer-based systems now outperform the best human diagnosticians on their own turf, identifying early stages of cancer and other diseases with unprecedented precision.

What does this imply about how we train doctors? Will we be encouraged to jettison huge chunks of traditional medical education, because machines can now do certain parts of the job more effectively?

As Dennett summarizes:

>_Use it or lose it_ is the rule of thumb cited at this point… how concerned should we be that we are dumbing ourselves down by our growing reliance on intelligent machines?

<!--small subscribe-->
<div class="course-promo darkradial-background subscribe text-center">
    <h4>In one concise email each Sunday, I break down a famous idea from philosophy. You get the distillation straight to your inbox:</h4>
    <div class="small-pad-top">
        <form action="https://app.convertkit.com/forms/5812400/subscriptions" method="post" data-sv-form="5812400" data-uid="be0e52d3c0" data-format="inline" data-version="6" data-options="{&quot;settings&quot;:{&quot;after_subscribe&quot;:{&quot;action&quot;:&quot;message&quot;,&quot;success_message&quot;:&quot;Thank you, philosopher! Your welcome email will land in your inbox shortly.&quot;,&quot;redirect_url&quot;:&quot;https://philosophybreak.com/thank-you/&quot;},&quot;analytics&quot;:{&quot;google&quot;:null,&quot;fathom&quot;:null,&quot;facebook&quot;:null,&quot;segment&quot;:null,&quot;pinterest&quot;:null,&quot;sparkloop&quot;:null,&quot;googletagmanager&quot;:null},&quot;modal&quot;:{&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;powered_by&quot;:{&quot;show&quot;:false,&quot;url&quot;:&quot;https://convertkit.com/features/forms?utm_campaign=poweredby&amp;utm_content=form&amp;utm_medium=referral&amp;utm_source=dynamic&quot;},&quot;recaptcha&quot;:{&quot;enabled&quot;:false},&quot;return_visitor&quot;:{&quot;action&quot;:&quot;show&quot;,&quot;custom_content&quot;:&quot;&quot;},&quot;slide_in&quot;:{&quot;display_in&quot;:&quot;bottom_right&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;sticky_bar&quot;:{&quot;display_in&quot;:&quot;top&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15}},&quot;version&quot;:&quot;6&quot;}" min-width="400 500 600 700 800">
        <div data-style="clean"><ul data-element="errors" data-group="alert"></ul><div data-element="fields" data-stacked="false">
            <div>
                <input name="email_address" aria-label="Your Email Address..." placeholder="Your Email Address..." required type="email" />
            </div>
            <button class="button primary" type="submit" data-element="submit"><div><div></div><div></div><div></div></div><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"/></svg>Join 11,500+ Subscribers</span></button>
            </div>
            </div>
        </form>
        <p class="tiny-mar-top no-mar-bottom review-font">💭 One short philosophical email each Sunday. Unsubscribe any time.</p>
    </div>
</div>

It could be argued that throughout history we’ve always used technology to make our lives easier, and that AI is just the latest ‘dangerous’ invention we’ll soon all calm down about.

However, the difference here is that while something like, say, a tractor replaces human labor, it doesn’t replace human comprehension: the human brain still plays a central role in plowing fields.

AI is different because it _does_ replace human comprehension: we cede not just labor but intellectual authority and expertise to the machine (i.e. tractors now come loaded with software, and perhaps one day this software will operate wholly independently, with no need for human oversight).

This, for Dennett, is what’s dangerous. What happens when the machines break? Will there be enough clued-up human experts to step in? If a coronal mass ejection from the sun were to wipe out global electronics, for example, are we confident civilization could survive?

As NASA states in an article on solar flares:

>In an increasingly technological world, where almost everyone relies on cell phones and GPS controls not just your in-car map system, but also airplane navigation and the extremely accurate clocks that govern financial transactions, space weather is a serious matter.

So, besides preparing our machines for such space weather, what can we do _culturally_ to prevent ourselves becoming too dependent on technology? How can we ensure we never overestimate the competence of machines to run societies on our behalf?

## Calling out the incompetencies in software

<span class="big-letter">O</span>ne of Dennett’s solutions to the problem of over-reliance is to make absolutely explicit the boundary between machines that are tools and those that claim to replace our comprehension. He writes:

>We should expose and ridicule all gratuitous anthropomorphism in systems, the cute, ever-more-human voices, the perky (but canned) asides. _When you are interacting with a computer, you should know you are interacting with a computer._

We should make it fashionable to identify and point out flaws in systems, Dennett argues. What’s more, we should write it into law that any advertisements for technology must acknowledge all shortcomings in the software — just like healthcare companies are obliged to list side effects.

As Dennett forcefully puts it:

>Systems that deliberately conceal their shortcuts and gaps of incompetence should be deemed fraudulent, and their creators should go to jail for committing the crime of creating or using an artificial intelligence that impersonates a human being.

This might seem alarmist, but Dennett’s argument should be considered in the context of how societies currently operate.

Comprehension is already spread thinly among various power structures. Politicians know some things; scientists and professors know some things; business leaders know some things; emergency services know some things — but nobody knows everything.

Specialization in society is rife. And if we start ceding that specialist knowledge to machines, then just as society becomes more complex humans will know less about how to deal with it.

We can reboot machines easily (and frequently do to fix problems); but we can’t reboot civilization without causing serious harm. As Dennett concludes:

>Civilization is a work in progress, and we abandon our attempt to understand it at our peril.

## What do you make of the discussion around AI?

- Do you think the development of AI is dangerous?
- Do you agree with Dennett’s proposals? Is anthropomorphism in technology a problem?
- Does the singularity pose a serious existential threat to society?
- Is our dependence on technology the more realistic path to civilization’s downfall?
- Or is all this talk of downfall merely alarmist thinking?

## Learn more about Dennett and philosophy

<span class="big-letter">I</span>f you’re interested in learning more about Dennett’s position, <a target="_blank" rel="noopener noreferrer sponsored" href="https://www.amazon.com/Bacteria-Bach-Back-Evolution-Minds-ebook/dp/B01HDSU2KY?&linkCode=ll1&tag=philosophybre-20&linkId=ed980bd711d48ce0e2e40cdd4c651278&language=en_US&ref_=as_li_ss_tl">From Bacteria to Bach and Back</a> is a wide-ranging and fascinating book. In addition to his reflection on technology discussed above, Dennett tackles some very challenging questions in typically entertaining style. What are the origins of language and culture? What is human consciousness? How did it become possible for our minds to even ask this question?

Dennett takes the reader on a riveting journey from natural selection and ‘design without a designer’ through to cultural evolution and the birth of intelligent (human) design.

For minds slipping into the warm, numbing embrace of machine intelligence, <a target="_blank" rel="noopener noreferrer sponsored" href="https://www.amazon.com/Bacteria-Bach-Back-Evolution-Minds-ebook/dp/B01HDSU2KY?&linkCode=ll1&tag=philosophybre-20&linkId=ed980bd711d48ce0e2e40cdd4c651278&language=en_US&ref_=as_li_ss_tl">From Bacteria to Bach and Back</a> is Dennett’s glorious bucket of ice-cold water, twisting human comprehension inside out.

You might also like the following related reads:

- [Do Neurons Push Thoughts Around? Or Do Thoughts Push Neurons Around?](/articles/do-neurons-push-thoughts-around-or-do-thoughts-push-neurons-around/)
- [Nozick’s Experience Machine: Does it Refute Hedonism?](/articles/nozick-experience-machine-vs-hedonism-should-you-plug-in/)
- [Consciousness: the Best 5 Books to Read](/reading-lists/consciousness/)

Finally, if you enjoyed this article, you might like my free Sunday breakdown. I distill one piece of wisdom from philosophy each week; you get the summary delivered straight to your email inbox, and are invited to share your view. Consider joining 11,500+ subscribers and signing up below:

<!--big subscribe-->
<div class="course-promo darkradial-background subscribe text-center">
    <img src="/static/6313d50bc32799a6c869239128784c7b/e7f7a/weekly-break.webp" alt="weekly emails from Philosophy Break">
    <h4>From the Buddha to Nietzsche: join 11,500+ subscribers enjoying my free Sunday Breakdown</h4>
    <p class="small-grey-font no-mar-bottom">In one concise email each Sunday, I break down a famous idea from philosophy. You get the distillation straight to your inbox.</p>
    <div class="small-pad-top">
        <form action="https://app.convertkit.com/forms/5812400/subscriptions" method="post" data-sv-form="5812400" data-uid="be0e52d3c0" data-format="inline" data-version="6" data-options="{&quot;settings&quot;:{&quot;after_subscribe&quot;:{&quot;action&quot;:&quot;message&quot;,&quot;success_message&quot;:&quot;Thank you, philosopher! Your welcome email will land in your inbox shortly.&quot;,&quot;redirect_url&quot;:&quot;https://philosophybreak.com/thank-you/&quot;},&quot;analytics&quot;:{&quot;google&quot;:null,&quot;fathom&quot;:null,&quot;facebook&quot;:null,&quot;segment&quot;:null,&quot;pinterest&quot;:null,&quot;sparkloop&quot;:null,&quot;googletagmanager&quot;:null},&quot;modal&quot;:{&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;powered_by&quot;:{&quot;show&quot;:false,&quot;url&quot;:&quot;https://convertkit.com/features/forms?utm_campaign=poweredby&amp;utm_content=form&amp;utm_medium=referral&amp;utm_source=dynamic&quot;},&quot;recaptcha&quot;:{&quot;enabled&quot;:false},&quot;return_visitor&quot;:{&quot;action&quot;:&quot;show&quot;,&quot;custom_content&quot;:&quot;&quot;},&quot;slide_in&quot;:{&quot;display_in&quot;:&quot;bottom_right&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;sticky_bar&quot;:{&quot;display_in&quot;:&quot;top&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15}},&quot;version&quot;:&quot;6&quot;}" min-width="400 500 600 700 800">
        <div data-style="clean"><ul data-element="errors" data-group="alert"></ul><div data-element="fields" data-stacked="false">
            <div>
                <input name="email_address" aria-label="Your Email Address..." placeholder="Your Email Address..." required type="email" />
            </div>
            <button class="button primary" type="submit" data-element="submit"><div><div></div><div></div><div></div></div><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"/></svg>Join 11,500+ Subscribers</span></button>
            </div>
            </div>
        </form>
        <p class="tiny-mar-top no-mar-bottom review-font">💭 One short philosophical email each Sunday. Unsubscribe any time.</p>
    </div>
</div>